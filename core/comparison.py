"""
æ¯”è¼ƒå’Œå·®ç•°é¡¯ç¤ºåŠŸèƒ½ - ç¢ºä¿ TABLE ä¸€å®šé¡¯ç¤º
"""
import os
import csv
import gzip
import json
import time
from datetime import datetime
from wcwidth import wcwidth
import config.settings as settings
from utils.logging import _get_display_width
from utils.helpers import get_file_mtime
from core.excel_parser import pretty_formula, extract_external_refs, get_excel_last_author
from core.baseline import load_baseline, baseline_file_path
import logging
import hashlib
import json as _json
import core.baseline as baseline

# ... [print_aligned_console_diff å’Œå…¶ä»–è¼”åŠ©å‡½æ•¸ä¿æŒä¸è®Š] ...
def print_aligned_console_diff(old_data, new_data, file_info=None, max_display_changes=0):
    """
    ä¸‰æ¬„å¼é¡¯ç¤ºï¼Œèƒ½è™•ç†ä¸­è‹±æ–‡å°é½Šï¼Œä¸¦æ­£ç¢ºé¡¯ç¤º formulaã€‚
    Address æ¬„å›ºå®šé—Šåº¦ï¼ŒBaseline/Current å¹³å‡åˆ†é…ã€‚
    """
    # çµ‚ç«¯å¯¬åº¦ï¼šå…è¨±è¨­å®šè¦†è“‹
    try:
        term_width = int(getattr(settings, 'CONSOLE_TERM_WIDTH_OVERRIDE', 0)) or os.get_terminal_size().columns
    except Exception:
        term_width = int(getattr(settings, 'CONSOLE_TERM_WIDTH_OVERRIDE', 0)) or 120

    # Address æ¬„å¯¬ï¼š0=è‡ªå‹•ï¼Œå¦å‰‡ç”¨è¨­å®šå€¼
    configured_addr_w = int(getattr(settings, 'ADDRESS_COL_WIDTH', 0))
    if configured_addr_w > 0:
        address_col_width = configured_addr_w
    else:
        # è‡ªå‹•ï¼šå–æœ¬æ¬¡è¦é¡¯ç¤ºè®Šæ›´çš„åœ°å€æœ€é•·é¡¯ç¤ºå¯¬åº¦èˆ‡ 6 å–å¤§è€…ï¼Œä½†ä¸è¶…é 16
        try:
            keys = list(set(old_data.keys()) | set(new_data.keys()))
            if keys:
                from utils.logging import _get_display_width
                max_addr = max((_get_display_width(k) or len(str(k)) for k in keys))
                address_col_width = max(6, min(16, max_addr))
            else:
                address_col_width = 10
        except Exception:
            address_col_width = 10

    separators_width = 4
    remaining_width = term_width - address_col_width - separators_width
    baseline_col_width = remaining_width // 2
    current_col_width = baseline_col_width  # å¼·åˆ¶å·¦å³ç­‰å¯¬ï¼Œç¢ºä¿è¦–è¦ºå°ç¨±

    def wrap_text(text, width):
        lines = []
        current_line = ""
        current_width = 0
        for char in str(text):
            char_width = wcwidth(char)
            if char_width < 0:
                continue
            if current_width + char_width > width:
                lines.append(current_line)
                current_line = char
                current_width = char_width
            else:
                current_line += char
                current_width += char_width
        if current_line:
            lines.append(current_line)
        return lines or ['']

    def pad_line(line, width):
        line_width = _get_display_width(line)
        if line_width is None:
            line_width = len(str(line))
        padding = width - line_width
        return str(line) + ' ' * padding if padding > 0 else str(line)

    def _strip_common_prefix(a: str, b: str):
        # æ‰¾å‡ºå…±åŒå‰ç¶´ï¼Œå›å‚³ (prefix, a_rest, b_rest)
        i = 0
        la, lb = len(a), len(b)
        while i < la and i < lb and a[i] == b[i]:
            i += 1
        return a[:i], a[i:], b[i:]

    def _maybe_highlight_diff(a: str, b: str):
        if not getattr(settings, 'DIFF_HIGHLIGHT_ENABLED', True):
            return a, b
        try:
            prefix, ar, br = _strip_common_prefix(a, b)
            if ar == '' and br == '':
                # å®Œå…¨ç›¸åŒ
                return a, b
            # ç”¨ Â«â€¦Â» æ¨™ç¤ºå·®ç•°å€æ®µé–‹é ­ï¼Œä¿ç•™å…±åŒå‰ç¶´ä¸€å°æ®µï¼ˆæœ€å¤š 16 å­—ï¼‰
            keep = prefix[-16:] if len(prefix) > 16 else prefix
            pa = (keep + 'Â«' + ar) if ar else keep
            pb = (keep + 'Â«' + br) if br else keep
            return pa, pb
        except Exception:
            return a, b

    def format_cell(cell_value):
        if cell_value is None or cell_value == {}:
            return "(Empty)"
        if isinstance(cell_value, dict):
            formula = cell_value.get("formula")
            if formula is not None and formula != "":
                fstr = str(formula)
                # é¿å…é‡è¤‡ç­‰è™Ÿï¼šå¦‚æœå·²ç¶“æ˜¯ä»¥ '=' é–‹é ­å°±ä¸è¦å†åŠ 
                return fstr if fstr.startswith('=') else f"={fstr}"
            if "value" in cell_value:
                return repr(cell_value["value"])
        return repr(cell_value)
    
    print()
    print("=" * term_width)
    if file_info:
        filename = file_info.get('filename', 'Unknown')
        worksheet = file_info.get('worksheet', '')
        event_number = file_info.get('event_number')
        file_path = file_info.get('file_path', filename)

        event_str = f"(äº‹ä»¶#{event_number}) " if event_number else ""
        caption = f"{event_str}{file_path} [Worksheet: {worksheet}]" if worksheet else f"{event_str}{file_path}"
        for cap_line in wrap_text(caption, term_width):
            print(cap_line)
    print("=" * term_width)

    baseline_time = file_info.get('baseline_time', 'N/A')
    current_time = file_info.get('current_time', 'N/A')
    old_author = file_info.get('old_author', 'N/A')
    new_author = file_info.get('new_author', 'N/A')

    header_addr = pad_line("Address", address_col_width)
    # æŠŠæ™‚é–“/ä½œè€…è³‡è¨Šæ”¹åˆ°ä¸‹ä¸€è¡Œï¼ˆå¯ç”±è¨­å®šæ§åˆ¶ï¼‰ï¼Œè®“ç¬¬ä¸€è¡Œæ¨™é ­æ›´çŸ­ï¼Œå…§å®¹æ¬„ä½æ›´å¯¬
    if getattr(settings, 'HEADER_INFO_SECOND_LINE', True):
        header_base = pad_line("Baseline", baseline_col_width)
        header_curr = pad_line("Current", current_col_width)
        print(f"{header_addr} | {header_base} | {header_curr}")
        # ç¬¬äºŒè¡Œé¡¯ç¤ºæ™‚é–“/ä½œè€…
        header2_base = pad_line(f"({baseline_time} by {old_author})", baseline_col_width)
        header2_curr = pad_line(f"({current_time} by {new_author})", current_col_width)
        print(f"{' ' * address_col_width} | {header2_base} | {header2_curr}")
    else:
        header_base = pad_line(f"Baseline ({baseline_time} by {old_author})", baseline_col_width)
        header_curr = pad_line(f"Current ({current_time} by {new_author})", current_col_width)
        print(f"{header_addr} | {header_base} | {header_curr}")
    print("-" * term_width)

    # è‡ªç„¶æ’åºï¼šA1, A2, A10ï¼ˆè€Œé A1, A10, A2ï¼‰
    import re
    def _addr_key(k):
        m = re.match(r"^([A-Za-z]+)(\d+)$", str(k))
        if not m:
            return (str(k), 0)
        col, row = m.group(1), int(m.group(2))
        return (col.upper(), row)
    all_keys = sorted(list(set(old_data.keys()) | set(new_data.keys())), key=_addr_key)
    if not all_keys:
        print("(No cell changes)")
    else:
        displayed_changes_count = 0
        for key in all_keys:
            if max_display_changes > 0 and displayed_changes_count >= max_display_changes:
                print(f"...(åƒ…é¡¯ç¤ºå‰ {max_display_changes} å€‹è®Šæ›´ï¼Œç¸½è¨ˆ {len(all_keys)} å€‹è®Šæ›´)...")
                break

            old_val = old_data.get(key)
            new_val = new_data.get(key)

            # ç§»é™¤ [ADD]/[MOD]/[DEL] æ¨™è¨˜ï¼Œè®“å·¦å³å…§å®¹æ›´å°ç¨±ã€ä¾¿æ–¼è¦–è¦ºå°æ¯”
            if old_val is not None and new_val is not None:
                old_text = format_cell(old_val)
                new_text = format_cell(new_val)
                # é«˜äº®å·®ç•°ï¼ˆåªåœ¨å…©è€…éƒ½æœ‰å…§å®¹æ™‚ï¼‰
                old_text, new_text = _maybe_highlight_diff(str(old_text), str(new_text))
            elif old_val is not None:
                old_text = format_cell(old_val)
                new_text = "(Deleted)"
            else:
                old_text = "(Empty)"
                new_text = format_cell(new_val)

            addr_lines = wrap_text(key, address_col_width)
            old_lines = wrap_text(old_text, baseline_col_width)
            new_lines = wrap_text(new_text, current_col_width)
            num_lines = max(len(addr_lines), len(old_lines), len(new_lines))
            for i in range(num_lines):
                a_line = addr_lines[i] if i < len(addr_lines) else ""
                o_line = old_lines[i] if i < len(old_lines) else ""
                n_line = new_lines[i] if i < len(new_lines) else ""
                formatted_a = pad_line(a_line, address_col_width)
                formatted_o = pad_line(o_line, baseline_col_width)
                formatted_n = n_line
                print(f"{formatted_a} | {formatted_o} | {formatted_n}")
            displayed_changes_count += 1
    print("=" * term_width)
    print()

def format_timestamp_for_display(timestamp_str):
    if not timestamp_str or timestamp_str == 'N/A':
        return 'N/A'
    try:
        if 'T' in timestamp_str:
            if '.' in timestamp_str:
                timestamp_str = timestamp_str.split('.')[0]
            return timestamp_str.replace('T', ' ')
        return timestamp_str
    except ValueError as e:
        logging.error(f"æ ¼å¼åŒ–æ™‚é–“æˆ³å¤±æ•—: {timestamp_str}, éŒ¯èª¤: {e}")
        return timestamp_str

def compare_excel_changes(file_path, silent=False, event_number=None, is_polling=False):
    """
    [æœ€çµ‚ä¿®æ­£ç‰ˆ] çµ±ä¸€æ—¥èªŒè¨˜éŒ„å’Œé¡¯ç¤ºé‚è¼¯
    """
    try:
        from core.excel_parser import dump_excel_cells_with_timeout
        
        from utils.helpers import _baseline_key_for_path
        base_key = _baseline_key_for_path(file_path)
        
        old_baseline = load_baseline(base_key)
        # å¿«é€Ÿè·³éï¼šè‹¥èˆ‡åŸºæº–ç·šçš„ mtime/size ä¸€è‡´ï¼ˆå®¹å·®å…§ï¼‰ï¼Œç›´æ¥åˆ¤å®šç„¡è®ŠåŒ–
        if settings.QUICK_SKIP_BY_STAT and old_baseline and \
           ("source_mtime" in old_baseline) and ("source_size" in old_baseline):
            try:
                cur_mtime = os.path.getmtime(file_path)
                cur_size  = os.path.getsize(file_path)
                base_mtime = float(old_baseline.get("source_mtime", 0))
                base_size  = int(old_baseline.get("source_size", -1))
                if (cur_size == base_size) and (abs(cur_mtime - base_mtime) <= float(getattr(settings,'MTIME_TOLERANCE_SEC',2.0))):
                    if not silent:
                        print(f"[å¿«é€Ÿé€šé] {os.path.basename(file_path)} mtime/size æœªè®Šï¼Œç•¥éè®€å–ã€‚")
                    return False
            except Exception:
                pass
        if old_baseline is None:
            old_baseline = {}

        current_data = dump_excel_cells_with_timeout(file_path, show_sheet_detail=False, silent=True)
        if not current_data:
            time.sleep(1)
            current_data = dump_excel_cells_with_timeout(file_path, show_sheet_detail=False, silent=True)
            if not current_data:
                if not silent:
                    print(f"âŒ é‡è©¦å¾Œä»ç„¡æ³•è®€å–æª”æ¡ˆ: {os.path.basename(file_path)}")
                return False
        
        baseline_cells = old_baseline.get('cells', {})
        if baseline_cells == current_data:
            # å¦‚æœæ˜¯è¼ªè©¢ä¸”ç„¡è®ŠåŒ–ï¼Œå‰‡ä¸é¡¯ç¤ºä»»ä½•å…§å®¹
            if is_polling:
                print(f"    [è¼ªè©¢æª¢æŸ¥] {os.path.basename(file_path)} å…§å®¹ç„¡è®ŠåŒ–ã€‚")
            return False
        
        any_sheet_has_changes = False
        
        old_author = old_baseline.get('last_author', 'N/A')
        try:
            new_author = get_excel_last_author(file_path)
        except Exception:
            new_author = 'Unknown'

        for worksheet_name in set(baseline_cells.keys()) | set(current_data.keys()):
            old_ws = baseline_cells.get(worksheet_name, {})
            new_ws = current_data.get(worksheet_name, {})
            
            if old_ws == new_ws:
                continue

            any_sheet_has_changes = True
            
            # åªæœ‰åœ¨ééœé»˜æ¨¡å¼ä¸‹æ‰é¡¯ç¤ºå’Œè¨˜éŒ„
            if not silent:
                baseline_timestamp = old_baseline.get('timestamp', 'N/A')
                current_timestamp = get_file_mtime(file_path)
                
                # åªé¡¯ç¤ºã€Œæœ‰æ„ç¾©è®Šæ›´ã€ï¼ˆéš±è—é–“æ¥è®Šæ›´/ç„¡æ„ç¾©è®Šæ›´ï¼‰
                meaningful_changes = analyze_meaningful_changes(old_ws, new_ws)
                if not meaningful_changes:
                    continue
                addrs = [c['address'] for c in meaningful_changes]
                display_old = {addr: old_ws.get(addr) for addr in addrs}
                display_new = {addr: new_ws.get(addr) for addr in addrs}

                # é¡¯ç¤ºæ¯”è¼ƒè¡¨ï¼ˆåƒ…æœ‰æ„ç¾©è®Šæ›´ï¼‰
                print_aligned_console_diff(
                    display_old,
                    display_new,
                    {
                        'filename': os.path.basename(file_path),
                        'file_path': file_path,
                        'event_number': event_number,
                        'worksheet': worksheet_name,
                        'baseline_time': format_timestamp_for_display(baseline_timestamp),
                        'current_time': format_timestamp_for_display(current_timestamp),
                        'old_author': old_author,
                        'new_author': new_author,
                    },
                    max_display_changes=settings.MAX_CHANGES_TO_DISPLAY
                )
                
                # åˆ†æä¸¦è¨˜éŒ„æœ‰æ„ç¾©çš„è®Šæ›´
                        # åˆ†æä¸¦è¨˜éŒ„æœ‰æ„ç¾©çš„è®Šæ›´ï¼ˆå¸¶å…¥è¨­å®šæ§åˆ¶ï¼‰
                meaningful_changes = analyze_meaningful_changes(old_ws, new_ws)
                if meaningful_changes:
                    # åªåœ¨éè¼ªè©¢çš„ç¬¬ä¸€æ¬¡æª¢æŸ¥æ™‚è¨˜éŒ„æ—¥èªŒï¼Œé¿å…é‡è¤‡
                    if not is_polling:
                        log_meaningful_changes_to_csv(file_path, worksheet_name, meaningful_changes, new_author)

        # ä»»ä½•å¯è¦‹çš„æ¯”è¼ƒï¼ˆééœé»˜ï¼‰ä¸”ç¢ºå¯¦æœ‰è®Šæ›´æ™‚ï¼Œå…ˆä¿å­˜æ­·å²å¿«ç…§ï¼Œå†ï¼ˆå¦‚å•Ÿç”¨ï¼‰æ›´æ–°åŸºæº–ç·š
        if any_sheet_has_changes and not silent:
            # MVPï¼šä¿å­˜å®Œæ•´å¿«ç…§ï¼ˆtimelineï¼‰
            try:
                from utils.history import save_history_snapshot, sync_history_to_git_repo, insert_event_index
                mc_count = 0
                try:
                    mc_count = sum(len(analyze_meaningful_changes(baseline_cells.get(ws, {}), current_data.get(ws, {}))) for ws in set(baseline_cells.keys()) | set(current_data.keys()))
                except Exception:
                    mc_count = 0
                # 1) ä¿å­˜å£“ç¸®å¿«ç…§ï¼ˆLOG_FOLDER/historyï¼‰
                snap_path = save_history_snapshot(file_path, current_data, last_author=new_author, event_number=event_number, meaningful_changes_count=mc_count)
                # 2) åŒæ­¥ç´” JSON åˆ° excel_git_repo ä¸¦ commitï¼ˆå¦‚ Git å¯ç”¨ï¼‰
                git_json_path = sync_history_to_git_repo(file_path, current_data, last_author=new_author, event_number=event_number, meaningful_changes_count=mc_count)
                # 3) æ’å…¥äº‹ä»¶ç´¢å¼•ï¼ˆSQLiteï¼‰
                try:
                    old_cells = (baseline.load_baseline(base_key) or {}).get('cells', {})
                except Exception:
                    old_cells = baseline_cells or {}
                insert_event_index(file_path,
                                   old_cells=old_cells,
                                   new_cells=current_data,
                                   last_author=new_author,
                                   event_number=event_number,
                                   snapshot_path=snap_path,
                                   summary_path=None,
                                   git_commit_sha=None,
                                   db_path=None)
            except Exception:
                pass
            if settings.AUTO_UPDATE_BASELINE_AFTER_COMPARE:
                print(f"ğŸ”„ è‡ªå‹•æ›´æ–°åŸºæº–ç·š: {os.path.basename(file_path)}")
                cur_mtime = os.path.getmtime(file_path)
                cur_size  = os.path.getsize(file_path)
                updated_baseline = {
                    "last_author": new_author,
                    "content_hash": f"updated_{int(time.time())}",
                    "cells": current_data,
                    "timestamp": datetime.now().isoformat(),
                     "source_mtime": cur_mtime,
                     "source_size": cur_size
                }
                if not baseline.save_baseline(base_key, updated_baseline):
                    print(f"[WARNING] åŸºæº–ç·šæ›´æ–°å¤±æ•—: {os.path.basename(file_path)}")
        
        return any_sheet_has_changes
        
    except Exception as e:
        if not silent:
            logging.error(f"æ¯”è¼ƒéç¨‹å‡ºéŒ¯: {e}")
        return False

def analyze_meaningful_changes(old_ws, new_ws):
    """
    ğŸ§  åˆ†ææœ‰æ„ç¾©çš„è®Šæ›´
    """
    meaningful_changes = []
    all_addresses = set(old_ws.keys()) | set(new_ws.keys())
    
    for addr in all_addresses:
        old_cell = old_ws.get(addr, {})
        new_cell = new_ws.get(addr, {})
        
        if old_cell == new_cell:
            continue

        change_type = classify_change_type(
            old_cell,
            new_cell,
            show_external_refresh=getattr(settings, 'SHOW_EXTERNAL_REFRESH_CHANGES', True),
            suppress_internal_same_value=getattr(settings, 'SUPPRESS_INTERNAL_FORMULA_CHANGE_WITH_SAME_VALUE', False),
            formula_only_mode=getattr(settings, 'FORMULA_ONLY_MODE', False),
        )
        
        # æ ¹æ“šè¨­å®šéæ¿¾è®Šæ›´
        if (
            change_type in ('FORMULA_CHANGE_INTERNAL', 'EXTERNAL_REF_LINK_CHANGE') and not settings.TRACK_FORMULA_CHANGES
        ) or (
            change_type == 'DIRECT_VALUE_CHANGE' and not settings.TRACK_DIRECT_VALUE_CHANGES
        ) or (
            change_type in ('EXTERNAL_REFRESH_UPDATE', 'EXTERNAL_REF_LINK_CHANGE') and not settings.TRACK_EXTERNAL_REFERENCES
        ) or (
            change_type == 'INDIRECT_CHANGE' and settings.IGNORE_INDIRECT_CHANGES
        ):
            continue

        # å°‡è¼¸å‡ºå€¼å„ªå…ˆç”¨ cached_valueï¼ˆè‹¥å­˜åœ¨ï¼‰
        def _disp(x):
            return x.get('cached_value') if x.get('cached_value') is not None else x.get('value')
        meaningful_changes.append({
            'address': addr,
            'old_value': _disp(old_cell),
            'new_value': _disp(new_cell),
            'old_formula': old_cell.get('formula'),
            'new_formula': new_cell.get('formula'),
            'change_type': change_type
        })
    
    return meaningful_changes

def classify_change_type(old_cell, new_cell, *, show_external_refresh=True, suppress_internal_same_value=False, formula_only_mode=False):
    """
    ğŸ” åˆ†é¡è®Šæ›´é¡å‹
    """
    old_val = old_cell.get('cached_value') if old_cell.get('cached_value') is not None else old_cell.get('value')
    new_val = new_cell.get('cached_value') if new_cell.get('cached_value') is not None else new_cell.get('value')
    old_formula = old_cell.get('formula')
    new_formula = new_cell.get('formula')

    if not old_cell and new_cell:
        return 'CELL_ADDED'
    if old_cell and not new_cell:
        return 'CELL_DELETED'

    # å…¬å¼è®Šæ›´ï¼šå¤–éƒ¨ vs å…§éƒ¨
    if old_formula != new_formula:
        if has_external_reference(old_formula) or has_external_reference(new_formula):
            return 'EXTERNAL_REF_LINK_CHANGE'
        # å…§éƒ¨å…¬å¼è®Šæ›´ï¼šå¯é¸æ“‡æ˜¯å¦æŠ‘åˆ¶åŒå€¼
        if suppress_internal_same_value and (old_val == new_val):
            return 'NO_CHANGE'
        return 'FORMULA_CHANGE_INTERNAL'

    # å…¬å¼æœªè®Šï¼šå¤–éƒ¨ refresh vs å…§éƒ¨é–“æ¥
    if old_formula and new_formula and old_val != new_val:
        if has_external_reference(old_formula):
            return 'EXTERNAL_REFRESH_UPDATE' if show_external_refresh else 'NO_CHANGE'
        else:
            return 'INDIRECT_CHANGE'

    # ç´”å€¼è®Šæ›´ï¼ˆéå…¬å¼ï¼‰
    if not old_formula and not new_formula and old_val != new_val:
        if formula_only_mode:
            return 'NO_CHANGE'
        return 'DIRECT_VALUE_CHANGE'

    return 'NO_CHANGE'

def has_external_reference(formula):
    if not formula: return False
    return "['" in formula or "!'" in formula

_recent_log_signatures = {}

def log_meaningful_changes_to_csv(file_path, worksheet_name, changes, current_author):
    """
    ğŸ“ è¨˜éŒ„æœ‰æ„ç¾©çš„è®Šæ›´åˆ° CSV (æœ€çµ‚çµ±ä¸€ç‰ˆ)
    - å¢åŠ éå»ä¸€æ®µæ™‚é–“å…§çš„å»é‡ï¼šç›¸åŒå…§å®¹åœ¨ LOG_DEDUP_WINDOW_SEC å…§ä¸æœƒé‡è¤‡è¨˜éŒ„
    """
    if not current_author or current_author == 'N/A' or not changes:
        return

    # æ§‹å»ºè®Šæ›´çš„ç©©å®šç°½åï¼ˆæª”å+è¡¨å+è®Šæ›´å…§å®¹ï¼‰
    try:
        # è¦ç¯„åŒ– changes é …ç›®ï¼ˆé¿å…ç›¸åŒå…§å®¹ä¸åŒé †åºé€ æˆç°½åä¸åŒï¼‰
        def _norm(x):
            return (
                str(x.get('address','')),
                str(x.get('change_type','')),
                _json.dumps(x.get('old_value', ''), ensure_ascii=False, sort_keys=True),
                _json.dumps(x.get('new_value', ''), ensure_ascii=False, sort_keys=True),
                str(x.get('old_formula','')),
                str(x.get('new_formula','')),
            )
        normalized_changes = sorted([_norm(c) for c in (changes or [])])
        payload = {
            'file': os.path.abspath(file_path),
            'sheet': worksheet_name,
            'changes': normalized_changes,
        }
        sig = hashlib.md5(_json.dumps(payload, sort_keys=True, ensure_ascii=False).encode('utf-8')).hexdigest()
        now = time.time()
        window = float(getattr(settings, 'LOG_DEDUP_WINDOW_SEC', 300))
        # æ¸…ç†éæœŸçš„ç°½å
        for k in list(_recent_log_signatures.keys()):
            if now - _recent_log_signatures[k] > window:
                _recent_log_signatures.pop(k, None)
        # å¦‚æœç°½åä»åœ¨æ™‚é–“çª—å…§ï¼Œè·³éè¨˜éŒ„
        if sig in _recent_log_signatures:
            return
        _recent_log_signatures[sig] = now
    except Exception:
        pass

    try:
        os.makedirs(os.path.dirname(settings.CSV_LOG_FILE), exist_ok=True)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        file_exists = os.path.exists(settings.CSV_LOG_FILE)
        
        with gzip.open(settings.CSV_LOG_FILE, 'at', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            
            if not file_exists:
                writer.writerow([
                    'Timestamp', 'Filename', 'Worksheet', 'Cell', 'Change_Type',
                    'Old_Value', 'New_Value', 'Old_Formula', 'New_Formula', 'Last_Author'
                ])
            
            for change in changes:
                writer.writerow([
                    timestamp,
                    os.path.basename(file_path),
                    worksheet_name,
                    change['address'],
                    change['change_type'],
                    change.get('old_value', ''),
                    change.get('new_value', ''),
                    change.get('old_formula', ''),
                    change.get('new_formula', ''),
                    current_author
                ])
        
        print(f"ğŸ“ {len(changes)} é …è®Šæ›´å·²è¨˜éŒ„åˆ° CSV")
        
    except (OSError, csv.Error) as e:
        logging.error(f"è¨˜éŒ„æœ‰æ„ç¾©çš„è®Šæ›´åˆ° CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# è¼”åŠ©å‡½æ•¸
def set_current_event_number(event_number):
    # é€™å€‹å‡½æ•¸å¯èƒ½ä¸å†éœ€è¦ï¼Œä½†æš«æ™‚ä¿ç•™
    pass